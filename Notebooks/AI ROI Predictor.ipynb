{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/AI Dataset.csv').drop('Unnamed: 0', axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['ROI'].copy().values\n",
    "X = df.copy().drop(['ROI'], axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91064655, 0.89783505, 0.89346121, 0.88289961, 0.89265775,\n",
       "       0.92244638, 0.89578358, 0.90599061, 0.89103276, 0.89526816,\n",
       "       0.8889555 , 0.88805119, 0.88296079, 0.88965163, 0.88476957,\n",
       "       0.88711287, 0.89599641, 0.88888005, 0.89403458, 0.88982135,\n",
       "       0.89062107, 0.88753561, 0.88958853, 0.89275569, 0.88930331,\n",
       "       0.95099687, 0.92179063, 0.9016578 , 0.8889477 , 0.88753198,\n",
       "       0.89746229, 0.89168453, 0.89208172, 0.89027436, 0.87541866,\n",
       "       0.89250262, 0.91055888, 0.88486898, 0.90462147, 0.88648425,\n",
       "       0.88739328, 0.89113423, 0.88191878, 0.88666836, 0.88488758,\n",
       "       0.88541454, 0.88892352, 0.8999447 , 0.88745441, 0.87450928,\n",
       "       0.89506944, 0.89048768, 0.88905176, 0.900517  , 0.88708798,\n",
       "       0.883011  , 0.8858593 , 0.89732546, 0.89345894, 0.89100697,\n",
       "       0.8974948 , 0.88523003, 0.87006805, 0.88599546, 0.89128832,\n",
       "       0.88836012, 0.87986507, 0.88916003, 0.88892363, 0.88891569,\n",
       "       0.88219951, 0.8857245 , 0.88820476, 0.91310344, 0.88408584,\n",
       "       0.88821113, 0.88901831, 0.8918539 , 0.88751785, 0.88889943,\n",
       "       0.88763465, 0.88739438, 0.89083575, 0.8910795 , 0.89925692,\n",
       "       0.90049039, 0.90579127, 0.89333592, 0.89078583, 0.87617468,\n",
       "       0.88758271, 0.88942256, 0.88620037, 0.88882852, 0.88893349,\n",
       "       0.88674952, 0.8889267 , 0.91168883, 0.88962323, 0.88903139,\n",
       "       0.88930563, 0.90003133, 0.88547713, 0.89291399, 0.88747532,\n",
       "       0.88970626, 0.88272759, 0.88641785, 0.88673036, 0.88898396,\n",
       "       0.88939845, 0.88690497, 0.88969082, 0.88696101, 0.89967787,\n",
       "       0.88984867, 0.89322062, 0.88532771, 0.88834883, 0.90750639,\n",
       "       0.89425784, 0.88953085, 0.88538899, 0.8821688 , 0.8897093 ,\n",
       "       0.88876123, 0.88633013, 0.88814   , 0.88593049, 0.88781341,\n",
       "       0.88411789, 0.8868738 , 0.88667986, 0.88897386, 0.89421982,\n",
       "       0.91723213, 0.89576919, 0.88440218, 0.89303335, 0.89246708,\n",
       "       0.88031974, 0.88939403, 0.89018308, 0.88282213, 0.88869149,\n",
       "       0.88727743, 0.89386015, 0.90151952, 0.88387857, 0.88387699,\n",
       "       0.86880221, 0.93059288, 0.88598935, 0.89190016, 0.8887777 ,\n",
       "       0.89667892, 0.88922   , 0.89243919, 0.88155114, 0.89240045,\n",
       "       0.89627878, 0.88893308, 0.88607401, 0.87758744, 0.91980168,\n",
       "       0.88779592, 0.88767562, 0.8754087 , 0.8821841 , 0.88199048,\n",
       "       0.89713623, 0.89947433, 0.90240146, 0.89217436, 0.88526051,\n",
       "       0.90647291, 0.91032194, 0.88895338, 0.8734794 , 0.88388418,\n",
       "       0.88763884, 0.88837916, 0.89888924, 0.89637908, 0.88502278,\n",
       "       0.88698748, 0.88875271, 0.90610492, 0.89480484, 0.89687119,\n",
       "       0.89297446, 0.88827545, 0.89475944, 0.89769193, 0.88460744,\n",
       "       0.88926679, 0.91281593, 0.88941092, 0.89221376, 0.89178014,\n",
       "       0.90709133, 0.88735001, 0.89410633, 0.88731829, 0.87809121,\n",
       "       0.88519495, 0.88722127, 0.89269429, 0.89456765, 0.9042488 ,\n",
       "       0.89796681, 0.89193109, 0.88749569, 0.90084115, 0.89705312,\n",
       "       0.89911754, 0.89152501, 0.90116987, 0.89043809, 0.88676163,\n",
       "       0.88570215, 0.88631501, 0.89509846, 0.89657592, 0.89185044,\n",
       "       0.88914103, 0.91414333, 0.88929039, 0.89385121, 0.88202777,\n",
       "       0.89295387, 0.88886423, 0.91125991, 0.88884775, 0.8994232 ,\n",
       "       0.89192049, 0.88834923, 0.88834865, 0.89932715, 0.87328784,\n",
       "       0.89821054, 0.89124911, 0.88386523, 0.88892021, 0.88320325,\n",
       "       0.88916482, 0.8890536 , 0.88199352, 0.91270277, 0.88436877,\n",
       "       0.88692025, 0.89949687, 0.88391107, 0.88274156, 0.89925902,\n",
       "       0.90111625, 0.89893597, 0.88508118, 0.87928975, 0.9038731 ,\n",
       "       0.88910717, 0.89353735, 0.89074297, 0.9058007 , 0.87841389,\n",
       "       0.88723867, 0.89146326, 0.89598237, 0.8892238 , 0.88559657,\n",
       "       0.88689475, 0.89096536, 0.89373854, 0.89676797, 0.89363898,\n",
       "       0.88096414, 0.92186185, 0.88964406, 0.89532598, 0.88942994,\n",
       "       0.88936628, 0.89994591, 0.88928392, 0.88784435, 0.90085596,\n",
       "       0.88613357, 0.88748114, 0.89171784, 0.8850316 , 0.89914017,\n",
       "       0.89866739, 0.89114337, 0.88780305, 0.89060333, 0.94134878,\n",
       "       0.88805867, 0.88933447, 0.89313661, 0.89367469, 0.88060855,\n",
       "       0.88915518, 0.88971888, 0.88503815, 0.89100587, 0.88726935,\n",
       "       0.89940875, 0.90102159, 0.89193493, 0.89094534, 0.89683092,\n",
       "       0.88853645, 0.88945144, 0.8926919 , 0.8970494 , 0.35991496,\n",
       "       0.88269214, 0.92074725, 0.89432252, 0.86875401, 0.90598813,\n",
       "       0.89231554, 0.90084619, 0.88951551, 0.89093009, 0.90478145,\n",
       "       0.89022315, 0.8897646 , 0.9022479 , 0.88118894, 0.88957963,\n",
       "       0.88615236, 0.88939013, 0.88493077, 0.8866245 , 0.90147365,\n",
       "       0.89157262, 0.90046023, 0.88924851, 0.8922295 , 0.89034722,\n",
       "       0.89214571, 0.88749618, 0.88409192, 0.89388341, 0.89734968,\n",
       "       0.88852628, 0.89501855, 0.89595411, 0.88907447, 0.90757997,\n",
       "       0.88910948, 0.89077794, 0.90401709, 0.88772905, 0.88857246,\n",
       "       0.9008098 , 0.8876666 , 0.88877912, 0.88709507, 0.8918683 ,\n",
       "       0.88604766, 0.88498652, 0.92564365, 0.8896177 , 0.86759552,\n",
       "       0.88890951, 0.88927391, 0.88906949, 0.92587208, 0.88769668,\n",
       "       0.8821089 , 0.89266496, 0.88548132, 0.89286552, 0.88864929,\n",
       "       0.89605059, 0.8883356 , 0.88913896, 0.89011354, 0.89087465,\n",
       "       0.89016085, 0.8766634 , 0.88883205, 0.88815391, 0.88793568,\n",
       "       0.88922861, 0.90592794, 0.88688615, 0.89039334, 0.89937002,\n",
       "       0.89343523, 0.88462003, 0.88230525, 0.88674929, 0.89785357,\n",
       "       0.9036494 , 0.88889047, 0.89339925, 0.88699679, 0.87595258,\n",
       "       0.89396884, 0.89063759, 0.88975976, 0.88852627, 0.88685936,\n",
       "       0.89591886, 0.88352846, 0.89251022, 0.89087787, 0.8967007 ,\n",
       "       0.87854105, 0.88526445, 0.89408484, 0.88776433, 0.88687319,\n",
       "       0.95136406, 0.87980638, 0.89068946, 0.88375855, 0.89054455,\n",
       "       0.89569655, 0.88639815, 0.8936872 , 0.87610599, 0.88878401,\n",
       "       0.880094  , 0.88246817, 0.88749982, 0.88711704, 0.89034747,\n",
       "       0.89427237, 0.88943821, 0.89577445, 0.88050098, 0.87919019,\n",
       "       0.90077097, 0.88353914, 0.88744678, 0.88649692, 0.88452875,\n",
       "       1.        , 0.89327295, 0.90374076, 0.88622552, 0.88896661,\n",
       "       0.88548334, 0.88563456, 0.88955763, 0.89686361, 0.88914292,\n",
       "       0.88922719, 0.88867639, 0.89197618, 0.89441469, 0.894935  ,\n",
       "       0.88542909, 0.88841869, 0.84880316, 0.88884603, 0.88788528,\n",
       "       0.88900924, 0.89019156, 0.8877659 , 0.91700424, 0.88961051,\n",
       "       0.89019962, 0.88081419, 0.89022376, 0.91093875, 0.89139982,\n",
       "       0.90068522, 0.90983658, 0.88872139, 0.88887817, 0.8870183 ,\n",
       "       0.88883288, 0.88440831, 0.91081885, 0.90699639, 0.8887252 ,\n",
       "       0.88893064, 0.88439548, 0.88437587, 0.88397027, 0.89116115,\n",
       "       0.8891224 , 0.88601302, 0.89213098, 0.88235694, 0.88101893,\n",
       "       0.88899833, 0.91256105, 0.88920808, 0.88303893, 0.88790741,\n",
       "       0.88723084, 0.90676965, 0.88538742, 0.88992193, 0.88392599,\n",
       "       0.88659863, 0.90347037, 0.88161816, 0.89344952, 0.88620951,\n",
       "       0.8893234 , 0.88635641, 0.87584751, 0.8951828 , 0.90783133,\n",
       "       0.88513512, 0.89087523, 0.8938991 , 0.88910211, 0.90187079,\n",
       "       0.88519029, 0.88121173, 0.89027082, 0.88039489, 0.88993786,\n",
       "       0.89816788, 0.88585751, 0.89177321, 0.91540675, 0.88699166,\n",
       "       0.89329357, 0.89108008, 0.88857492, 0.86589395, 0.88728356,\n",
       "       0.88947399, 0.88916425, 0.88743219, 0.89109675, 0.89019641,\n",
       "       0.886899  , 0.89834243, 0.88839638, 0.88829384, 0.88315067,\n",
       "       0.89358728, 0.89082973, 0.89376028, 0.88052025, 0.89239582,\n",
       "       0.89036809, 0.89200688, 0.88919294, 0.88963876, 0.89377815,\n",
       "       0.88867983, 0.8715109 , 0.88835752, 0.88549747, 0.89946215,\n",
       "       0.8891522 , 0.86193396, 0.89149068, 0.8975187 , 0.88381289,\n",
       "       0.9050456 , 0.88869171, 0.94283562, 0.88856031, 0.90045373,\n",
       "       0.89697067, 0.89557362, 0.89214156, 0.89320889, 0.90310287,\n",
       "       0.88602707, 0.88876464, 0.8916328 , 0.8846827 , 0.88708672,\n",
       "       0.88725828, 0.89396487, 0.88988151, 0.88848993, 0.92602178,\n",
       "       0.88990022, 0.88479181, 0.8804567 , 0.91194055, 0.89465214,\n",
       "       0.89056211, 0.89258309, 0.90108622, 0.88826815, 0.89115263,\n",
       "       0.8882529 , 0.88657169, 0.88204095, 0.8933022 , 0.88927743,\n",
       "       0.88906598, 0.88753448, 0.87153174, 0.89109172, 0.88057848,\n",
       "       0.88666163, 0.89402127, 0.88219008, 0.89769584, 0.89086553,\n",
       "       0.87842938, 0.87873917, 0.91334801, 0.88888416, 0.88995838,\n",
       "       0.88999861, 0.87438018, 0.87989226, 0.92318937, 0.88637044,\n",
       "       0.90366522, 0.88909354, 0.88706084, 0.89158025, 0.89601558,\n",
       "       0.89402004, 0.88769292, 0.89085822, 0.88997414, 0.89411563,\n",
       "       0.89215173, 0.88990975, 0.88832252, 0.89812996, 0.8928579 ,\n",
       "       0.88920119, 0.88795653, 0.89291706, 0.89017464, 0.88840236,\n",
       "       0.88758276, 0.90542523, 0.88621049, 0.88628689, 0.88857324,\n",
       "       0.88368156, 0.89612215, 0.89471207, 0.88159647, 0.88816932,\n",
       "       0.89265967, 0.8941049 , 0.89392997, 0.87950695, 0.89273776,\n",
       "       0.88547472, 0.88914654, 0.89854148, 0.88552897, 0.89064778,\n",
       "       0.89304746, 0.89001751, 0.89095047, 0.88462561, 0.90177681,\n",
       "       0.90729833, 0.89903913, 0.88896305, 0.89503038, 0.88602242,\n",
       "       0.89880309, 0.8824004 , 0.88772241, 0.88681583, 0.88183187,\n",
       "       0.9009621 , 0.8971123 , 0.88937673, 0.88977908, 0.88707513,\n",
       "       0.88393632, 0.88899176, 0.9113845 , 0.88839697, 0.89112961,\n",
       "       0.89230331, 0.88885673, 0.88621446, 0.89162574, 0.88868936,\n",
       "       0.93407102, 0.88898176, 0.88705286, 0.87731992, 0.8909464 ,\n",
       "       0.89157547, 0.89376942, 0.90669524, 0.89527272, 0.88514514,\n",
       "       0.88905259, 0.89439611, 0.88393139, 0.88907661, 0.89415805,\n",
       "       0.88853104, 0.92210514, 0.87851576, 0.89367557, 0.89932081,\n",
       "       0.886939  , 0.88881631, 0.88072374, 0.88644178, 0.89524465,\n",
       "       0.88862165, 0.89301858, 0.88787918, 0.88422248, 0.88596564,\n",
       "       0.89245569, 0.93111265, 0.89898875, 0.88894335, 0.88748965,\n",
       "       0.89341297, 0.88853611, 0.89737044, 0.8849732 , 0.96914821,\n",
       "       0.88888214, 0.884956  , 0.89425158, 0.88887649, 0.90025064,\n",
       "       0.89158882, 0.88456343])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.89242966, 0.89442284, 0.89789912, ..., 0.88773243, 0.88672388,\n       0.8882671 ]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-886a67409487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       \u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                       random_state=42)\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\pyviz\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyviz\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    362\u001b[0m                       (not self.warm_start and not incremental))\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyviz\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[0;32m    996\u001b[0m         ):\n\u001b[0;32m    997\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyviz\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pyviz\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0.89242966, 0.89442284, 0.89789912, ..., 0.88773243, 0.88672388,\n       0.8882671 ]),)"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(solver='adam', \n",
    "                      max_iter=10000,\n",
    "                      alpha=1e-5,\n",
    "                      learning_rate='adaptive',\n",
    "                      hidden_layer_sizes=(150,), \n",
    "                      random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
